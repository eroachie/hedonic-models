{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial on Hedonic Regression\n",
    "\n",
    "This material uses Python to demonstrate some aspects of hedonic regression. The objective here is not to learn to program, but to understand the hedonic regression methodology.  We begin with an example in which we generate some synthetic data using a set of coefficients and a mathematical model, and learn those coefficients using a statistical method called multiple regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part of this notebook follows closely the content in the Statsmodels online documentation. We won't try to provide the theoretical basis for regression models here.  You can consult any number of online resources for this, including Wikipedia's explanation of [Ordinary Least Squares Regression](https://en.wikipedia.org/wiki/Ordinary_least_squares). We will be using the Statsmodels library for this ([documentation here](http://statsmodels.sourceforge.net/stable/index.html)).\n",
    "\n",
    "The statistical model is assumed to be $Y = X\\beta + \\epsilon$, where $\\epsilon\\sim N\\left(0,\\sigma^{2}\\Sigma\\right)$\n",
    "\n",
    "Depending on the assumption on $\\Sigma$, Statsmodels have currently four classes available\n",
    "\n",
    "- GLS : generalized least squares for arbitrary covariance $\\Sigma$\n",
    "- OLS : ordinary least squares for i.i.d. errors $\\Sigma=\\textbf{I}$\n",
    "- WLS : weighted least squares for heteroskedastic errors $\\text{diag}\\left  (\\Sigma\\right)$\n",
    "- GLSAR : feasible generalized least squares with autocorrelated AR(p) errors $\\Sigma=\\Sigma\\left(\\rho\\right)$\n",
    "\n",
    "We focus here on the simple Ordinary Least Squares (OLS) model that is the most widely used, but makes strong assumptions about the errors being indepentently and identically distributed (i.i.d.).  When these conditions are met, the OLS parameter estimates are the Best Linear Unbiased Estimates (BLUE).\n",
    "\n",
    "More intuitively (perhaps), what linear regression using the OLS estimator attempts to do is find the vector of parameters ($\\beta$), such that when you compute a linear function $X\\beta$ you generate a predicted array of $\\hat{y}$ that, compared to the observed $y$, the squared sum of each observation's error ($\\epsilon_{i} = \\hat{y}_{i} - y_{i}$) across all the observations ($\\Sigma^{2}\\epsilon_{i}$), is minimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Startup steps\n",
    "import pandas as pd, numpy as np, statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt, matplotlib.cm as cm, matplotlib.font_manager as fm\n",
    "import matplotlib.mlab as mlab\n",
    "from scipy.stats import pearsonr, ttest_rel\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data using a model we define:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nsample = 50\n",
    "x = np.linspace(0, 10, 50)\n",
    "X = x\n",
    "beta = np.array([0, 2])\n",
    "e = np.random.normal(size=nsample)\n",
    "X = sm.add_constant(X)\n",
    "y = np.dot(X, beta) + e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the data as a scatterplot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(10,8), )\n",
    "plt.scatter(x, y, marker=0, s=10, c='g')\n",
    "plt.axis([0, 10, 0, 20])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add line based on Intercept = 0, beta = slope of line = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(10,8), )\n",
    "plt.plot([0, 10], [0, 20])\n",
    "plt.scatter(x, y, marker=0, s=10, c='g')\n",
    "plt.axis([0, 10, 0, 20])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regenerate the data using an intercept = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nsample = 20\n",
    "x = np.linspace(0, 10, 20)\n",
    "X = x\n",
    "beta = np.array([2, 2])\n",
    "e = np.random.normal(size=nsample)\n",
    "X = sm.add_constant(X)\n",
    "y = np.dot(X, beta) + e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying regression models using design matrices (dmatrices) in statsmodels\n",
    "\n",
    "To fit most of the models covered by statsmodels, you will need to create two design matrices. The first is a matrix of endogenous variable(s) (i.e. dependent, response, regressand, etc.). The second is a matrix of exogenous variable(s) (i.e. independent, predictor, regressor, etc.). The OLS coefficient estimates are calculated using linear algebra to find the parameters that minimize the sum of the squared errors:\n",
    "\n",
    "$$\\hat{\\beta} = (X'X)^{-1} X'y$$\n",
    "\n",
    "where $y$ is an $N \\times 1$ column of data on sales price. $X$ is $N \\times 2$ with an intercept and the x variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a simple linear regression and compare the coefficients to the ones used to generate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Parameters: ', results.params)\n",
    "inter = results.params[0]\n",
    "beta = results.params[1]\n",
    "print('Intercept =', inter)\n",
    "print('Beta = ', beta)\n",
    "print('Rsquared = ', results.rsquared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Rsquared = Explained Variation / Total Variation\n",
    " \n",
    " Rsquared = 1 - (Unexplained Variation / Total Variation)\n",
    " \n",
    " Rsquared = 1 â€“ (sum of squared residuals / sum of squared deviation of prices from the mean price)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the 'true' line using the original coefficients, and the 'predicted' line, using the estimated coefficients.  Try with smaller and larger samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(10,8), )\n",
    "plt.plot([0, 10], [2, 22], c='r')\n",
    "plt.plot([0,10], [inter,(inter+10*beta)], c='b')\n",
    "plt.scatter(x, y, marker=0, s=10, c='g')\n",
    "plt.axis([0, 10, 0, 22])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Now on to some real data and Hedonic Regression\n",
    "\n",
    "We will use a large sample of single family housing sales from the San Francisco Bay Area to estimate a linear regression model in which the dependent variable $y$ is the price of a house at the time of sale, and $X$ is a set of exogenous, or explanatory variables.\n",
    "\n",
    "What exactly does this give us?  A statistical way to figure out what the component amenities in a house are worth, if you could buy them *a la carte*.  Another way to think of it is, how much do house buyers in the Bay Area during this period pay, on average, for an additional unit of each amenity: square foot of living space, bedroom, bathroom, etc.\n",
    "\n",
    "Here we use the sales transactions in San Francisco over a month from early-February through early-March.\n",
    "\n",
    "First we load the data from a csv file.  Then we rename columns to make the data easier to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sf = pd.read_csv('data/redfin_2017-03-05-17-45-34-san-francisco-county-1-month.csv')\n",
    "sf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sf1 = sf.rename(index=str, columns={'SALE TYPE': 'saletype',\n",
    "    'SOLD DATE': 'solddate', 'PROPERTY TYPE': 'proptype', 'ADDRESS': 'address',\n",
    "    'CITY': 'city', 'STATE': 'state', 'ZIP': 'zip', 'PRICE': 'price', 'BEDS': 'beds',\n",
    "    'BATHS': 'baths', 'LOCATION': 'location', 'SQUARE FEET': 'sqft', 'LOT SIZE': 'lotsize',\n",
    "    'YEAR BUILT': 'yrbuilt', 'DAYS ON MARKET': 'daysonmkt', '$/SQUARE FEET': 'pricesqft',\n",
    "    'LATITUDE': 'latitude', 'LONGITUDE': 'longitude', 'HOA/MONTH': 'hoamonth',\n",
    "    'URL (SEE http://www.redfin.com/buy-a-home/comparative-market-analysis FOR INFO ON PRICING)': 'url',\n",
    "    'STATUS': 'status', 'NEXT OPEN HOUSE START TIME': 'nextopenstart', 'NEXT OPEN HOUSE END TIME': 'nextopenend',\n",
    "    'SOURCE': 'source', 'MLS#': 'mls', 'FAVORITE': 'favorite', 'INTERESTED': 'interested'\n",
    "    })\n",
    "\n",
    "sf1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sf1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is a scatterplot of sqft and price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(10,8), )\n",
    "plt.scatter(sf1['sqft'], sf1['price'], marker=0, s=10, c='g')\n",
    "#plt.axis([12, 16, 12, 16])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is a scatterplot of beds and price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(10,8), )\n",
    "plt.scatter(sf1['beds'], sf1['price'], marker=0, s=10, c='g')\n",
    "#plt.axis([12, 16, 12, 16])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating correlations among multiple variables and price\n",
    "What if we want to know how price is affected by both sqft and beds, and other variables as well?  We would generally use multiple regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recoding variables\n",
    "\n",
    "Sometimes variables have larger values than you intend to use. You can either drop those records, or recode the data so that values above some limit are capped at that limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sf1['beds4'] = sf1['beds']\n",
    "sf1['baths4'] = sf1['baths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sf1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the maximum bedrooms is 18 and the maximum bathrooms is 5.5, let's create a recoded version of these to cap the maximum value at 4 for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sf1.loc[:,'beds4'][sf1['beds']>3] =  4\n",
    "#sf1.loc[:,'baths4'][sf1['baths']>3] =  4\n",
    "sf1.loc[sf1.beds > 3, 'beds4'] =  4\n",
    "sf1.loc[sf1.baths > 3, 'baths4'] =  4\n",
    "\n",
    "sf1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's estimate a series of models using the sales data.\n",
    "\n",
    "Here we specify models using R syntax.  This uses the patsy language\n",
    "See http://patsy.readthedocs.org/en/latest/ for complete documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from patsy import dmatrices\n",
    "y, X = dmatrices('np.log(price) ~ np.log(sqft) + beds + baths', \n",
    "                 data=sf1, return_type='dataframe')\n",
    "mod = sm.OLS(y, X)\n",
    "res = mod.fit()\n",
    "residuals = res.resid\n",
    "predicted = res.fittedvalues\n",
    "observed = y\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with the log transformations and practice interpretation\n",
    "\n",
    "Most hedonic regression models use a log-transformation of the dependent variable (price), by taking the logarithm of the price of each sale and using it as the dependent variable.  It changes the interpretation of the coefficients.  If the variable on the right hand side is untransformed (in its original scale) and the dependent variable is log-transformed, then one unit increase in the right hand side variable is predicted to increase the price of a house by the percentage indicated by the coefficient.  If the right hand side variable is also log transformed, then the interpretation is one percent change in the independent variable is associated with the percentage change in the dependent variable indicated by the coefficient.  If neither is transformed, then the coefficient indicates the dollar amount of change in price expected from a one unit change in the independent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How well the does model fit the data?\n",
    "\n",
    "The errors appear to be normally distributed - with half having positive errors and half having negative errors, and the mean value being zero.  This is one indicator of whether the model is inacurate (statistically biased)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(residuals, bins=25, normed=True, alpha=.5)\n",
    "mu = residuals.mean()\n",
    "variance = residuals.var()\n",
    "sigma = residuals.std()\n",
    "x = np.linspace(-3, 3, 100)\n",
    "plt.plot(x,mlab.normpdf(x, mu, sigma));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to look at these results is to plot the errors against the range of the y variable, to see if the errors appear to be higher at one end of the range of y or the other.  It seems to be fairly uniform across the scale of y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(10,8), )\n",
    "plt.plot([12, 16], [0, 0], c='b')\n",
    "plt.scatter(predicted, residuals, marker=0, s=10, c='g');\n",
    "plt.axis([12, 16, -0.8, 0.8])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next plot compares observed values on the x axis to predicted values from the model on the y axis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(10,8), )\n",
    "plt.plot([12, 16], [12, 16])\n",
    "plt.scatter(observed, predicted, marker=0, s=10, c='g')\n",
    "plt.axis([12, 16, 12, 16])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
